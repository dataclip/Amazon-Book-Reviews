{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Book Reviews Part IV: Hypothesis Testing \n",
    "\n",
    "#### This is the 5-core dataset which means that each user and item has at least 5 reviews.  It has ~9 million reviews: http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "#### Introduction \n",
    "\n",
    "1. Overall ratings are divided into two categories where 4 & 5 star ratings are positive reviews. Helpfulness is also divided into two categories and below 50% is 'NOT' helpful. \n",
    "2. We test here if the high star ratings are associated with a better helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.io import gbq\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats.api as sms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query1 = \"SELECT overall, percHelpful FROM amazon_book_small.help_length \\\n",
    "WHERE unixReviewTime >= '1996-01-01 00:00:00 UTC' AND unixReviewTime < '2012-01-01 00:00:00 UTC'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_id = 'dotted-chiller-156222'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Query running...\n",
      "Query done.\n",
      "Processed: 172.1 Mb\n",
      "\n",
      "Retrieving results...\n",
      "  Got page: 1; 4.0% done. Elapsed 15.94 s.\n",
      "  Got page: 2; 7.0% done. Elapsed 19.61 s.\n",
      "  Got page: 3; 11.0% done. Elapsed 23.62 s.\n",
      "  Got page: 4; 14.0% done. Elapsed 27.79 s.\n",
      "  Got page: 5; 18.0% done. Elapsed 31.99 s.\n",
      "  Got page: 6; 22.0% done. Elapsed 36.33 s.\n",
      "  Got page: 7; 25.0% done. Elapsed 41.17 s.\n",
      "  Got page: 8; 29.0% done. Elapsed 45.84 s.\n",
      "  Got page: 9; 33.0% done. Elapsed 48.79 s.\n",
      "  Got page: 10; 36.0% done. Elapsed 53.26 s.\n",
      "  Got page: 11; 40.0% done. Elapsed 56.74 s.\n",
      "  Got page: 12; 43.0% done. Elapsed 60.37 s.\n",
      "  Got page: 13; 47.0% done. Elapsed 65.09 s.\n",
      "  Got page: 14; 51.0% done. Elapsed 69.77 s.\n",
      "  Got page: 15; 54.0% done. Elapsed 73.78 s.\n",
      "  Got page: 16; 58.0% done. Elapsed 78.28 s.\n",
      "  Got page: 17; 61.0% done. Elapsed 81.89 s.\n",
      "  Got page: 18; 65.0% done. Elapsed 85.95 s.\n",
      "  Got page: 19; 69.0% done. Elapsed 89.46 s.\n",
      "  Got page: 20; 72.0% done. Elapsed 94.43 s.\n",
      "  Got page: 21; 76.0% done. Elapsed 98.25 s.\n",
      "  Got page: 22; 80.0% done. Elapsed 101.52 s.\n",
      "  Got page: 23; 83.0% done. Elapsed 105.16 s.\n",
      "  Got page: 24; 87.0% done. Elapsed 108.62 s.\n",
      "  Got page: 25; 90.0% done. Elapsed 112.26 s.\n",
      "  Got page: 26; 94.0% done. Elapsed 117.69 s.\n",
      "  Got page: 27; 98.0% done. Elapsed 121.6 s.\n",
      "  Got page: 28; 100.0% done. Elapsed 124.25 s.\n",
      "Got 2765535 rows.\n",
      "\n",
      "Total time taken 143.13 s.\n",
      "Finished at 2017-01-25 12:33:10.\n"
     ]
    }
   ],
   "source": [
    "da = gbq.read_gbq(query1, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>percHelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  percHelpful\n",
       "0        5          0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query2 = \"SELECT overall, percHelpful FROM amazon_book_small.help_length \\\n",
    "WHERE unixReviewTime >= '2012-01-02 00:00:00 UTC' AND unixReviewTime < '2015-01-01 00:00:00 UTC'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting query... ok.\n",
      "Query running...\n",
      "  Elapsed 11.15 s. Waiting...\n",
      "Query done.\n",
      "Processed: 172.1 Mb\n",
      "\n",
      "Retrieving results...\n",
      "  Got page: 1; 2.0% done. Elapsed 19.92 s.\n",
      "  Got page: 2; 3.0% done. Elapsed 22.8 s.\n",
      "  Got page: 3; 5.0% done. Elapsed 26.19 s.\n",
      "  Got page: 4; 7.0% done. Elapsed 30.63 s.\n",
      "  Got page: 5; 8.0% done. Elapsed 34.15 s.\n",
      "  Got page: 6; 10.0% done. Elapsed 37.75 s.\n",
      "  Got page: 7; 11.0% done. Elapsed 42.37 s.\n",
      "  Got page: 8; 13.0% done. Elapsed 45.51 s.\n",
      "  Got page: 9; 15.0% done. Elapsed 49.19 s.\n",
      "  Got page: 10; 16.0% done. Elapsed 52.7 s.\n",
      "  Got page: 11; 18.0% done. Elapsed 57.08 s.\n",
      "  Got page: 12; 20.0% done. Elapsed 61.29 s.\n",
      "  Got page: 13; 21.0% done. Elapsed 65.74 s.\n",
      "  Got page: 14; 23.0% done. Elapsed 69.04 s.\n",
      "  Got page: 15; 24.0% done. Elapsed 72.56 s.\n",
      "  Got page: 16; 26.0% done. Elapsed 76.67 s.\n",
      "  Got page: 17; 28.0% done. Elapsed 80.69 s.\n",
      "  Got page: 18; 29.0% done. Elapsed 84.85 s.\n",
      "  Got page: 19; 31.0% done. Elapsed 88.09 s.\n",
      "  Got page: 20; 33.0% done. Elapsed 91.72 s.\n",
      "  Got page: 21; 34.0% done. Elapsed 96.01 s.\n",
      "  Got page: 22; 36.0% done. Elapsed 99.8 s.\n",
      "  Got page: 23; 38.0% done. Elapsed 102.87 s.\n",
      "  Got page: 24; 39.0% done. Elapsed 106.58 s.\n",
      "  Got page: 25; 41.0% done. Elapsed 110.14 s.\n",
      "  Got page: 26; 42.0% done. Elapsed 114.27 s.\n",
      "  Got page: 27; 44.0% done. Elapsed 118.03 s.\n",
      "  Got page: 28; 46.0% done. Elapsed 121.54 s.\n",
      "  Got page: 29; 47.0% done. Elapsed 124.97 s.\n",
      "  Got page: 30; 49.0% done. Elapsed 128.26 s.\n",
      "  Got page: 31; 51.0% done. Elapsed 131.59 s.\n",
      "  Got page: 32; 52.0% done. Elapsed 135.24 s.\n",
      "  Got page: 33; 54.0% done. Elapsed 139.52 s.\n",
      "  Got page: 34; 55.0% done. Elapsed 143.84 s.\n",
      "  Got page: 35; 57.0% done. Elapsed 147.13 s.\n",
      "  Got page: 36; 59.0% done. Elapsed 150.4 s.\n",
      "  Got page: 37; 60.0% done. Elapsed 154.14 s.\n",
      "  Got page: 38; 62.0% done. Elapsed 157.93 s.\n",
      "  Got page: 39; 64.0% done. Elapsed 161.25 s.\n",
      "  Got page: 40; 65.0% done. Elapsed 164.94 s.\n",
      "  Got page: 41; 67.0% done. Elapsed 170.61 s.\n",
      "  Got page: 42; 69.0% done. Elapsed 174.33 s.\n",
      "  Got page: 43; 70.0% done. Elapsed 178.11 s.\n",
      "  Got page: 44; 72.0% done. Elapsed 181.34 s.\n",
      "  Got page: 45; 73.0% done. Elapsed 184.62 s.\n",
      "  Got page: 46; 75.0% done. Elapsed 188.31 s.\n",
      "  Got page: 47; 77.0% done. Elapsed 191.39 s.\n",
      "  Got page: 48; 78.0% done. Elapsed 195.08 s.\n",
      "  Got page: 49; 80.0% done. Elapsed 199.05 s.\n",
      "  Got page: 50; 82.0% done. Elapsed 202.43 s.\n",
      "  Got page: 51; 83.0% done. Elapsed 208.42 s.\n",
      "  Got page: 52; 85.0% done. Elapsed 212.07 s.\n",
      "  Got page: 53; 86.0% done. Elapsed 215.24 s.\n",
      "  Got page: 54; 88.0% done. Elapsed 218.82 s.\n",
      "  Got page: 55; 90.0% done. Elapsed 223.28 s.\n",
      "  Got page: 56; 91.0% done. Elapsed 226.9 s.\n",
      "  Got page: 57; 93.0% done. Elapsed 230.78 s.\n",
      "  Got page: 58; 95.0% done. Elapsed 235.43 s.\n",
      "  Got page: 59; 96.0% done. Elapsed 239.14 s.\n",
      "  Got page: 60; 98.0% done. Elapsed 243.01 s.\n",
      "  Got page: 61; 100.0% done. Elapsed 246.58 s.\n",
      "  Got page: 62; 100.0% done. Elapsed 248.25 s.\n",
      "Got 6130337 rows.\n",
      "\n",
      "Total time taken 301.3 s.\n",
      "Finished at 2017-01-25 12:39:37.\n"
     ]
    }
   ],
   "source": [
    "db = gbq.read_gbq(query2, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>percHelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  percHelpful\n",
       "0        5          0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([da, db])\n",
    "df = df.fillna(0)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8895872, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A percentage rating column were prepared in bigQuery based on (yes vote/total vote). Note that 90/100 will have the same percentage rating as 9/10 but I am not taking the weighted average and assuming that 0.9% carries the same weight throughout. \n",
    "\n",
    "### Function to make overall ratings positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x < 3.0:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "rating = df['overall']\n",
    "rating = rating.map(partition)\n",
    "\n",
    "tmp = df\n",
    "tmp['overall'] = tmp['overall'].map(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>percHelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall  percHelpful\n",
       "0  positive     0.000000\n",
       "1  positive     0.857143\n",
       "2  positive     0.666667\n",
       "3  positive     0.571429\n",
       "4  positive     0.971429"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to make helpfulness useful (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>percHelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall  percHelpful\n",
       "0  positive          0.0\n",
       "1  positive          1.0\n",
       "2  positive          1.0\n",
       "3  positive          1.0\n",
       "4  positive          1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partitionP(x):\n",
    "    if x < 0.5:\n",
    "        return 0.0\n",
    "    return 1.0\n",
    "\n",
    "rating = df['percHelpful']\n",
    "rating = rating.map(partitionP)\n",
    "tmp = df\n",
    "tmp['percHelpful'] = tmp['percHelpful'].map(partitionP)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8895872"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(tmp)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8157203"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = len(tmp[tmp.overall == 'positive'])\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8157203"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = len(tmp[tmp.overall == 'positive'])\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "738669"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = len(tmp[tmp.overall == 'negative'])\n",
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9169649698197097"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_frac = float(pos)/float(total)\n",
    "pos_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 92% of the total reviews are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08303503018029035"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_frac = (1.0 -pos_frac)\n",
    "neg_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to chose 20000 random reviews from the original dataset to test the hypothesis. Since the positive to negative ratio is ~ 9:1 in the original dataset we will take a sample preserving the same ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "dj = df.iloc[sample(range(len(df)), 20000), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18352"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dj[dj.overall == 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1648"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dj[dj.overall == 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7838.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dj[dj.overall=='positive'].percHelpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dj[dj.overall =='negative'].percHelpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4270924149956408"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posYes = 7838.0/18352.0\n",
    "posYes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5115291262135923"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negYes = 843.0/1648.0\n",
    "negYes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08443671121795143"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negYes - posYes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this sample, we see that negative reviewers got a better helpfulness rating by 8%. We will test the statistical significance of this statement. \n",
    "\n",
    "<p> Null hypothesis is that there is no difference, i.e., posYes = negYes. Samples are chosen randomly, let's calculate $\\hat{p}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43405"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phat calculation \n",
    "p_exp = (7838.0+843)/20000.0\n",
    "p_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715.3144"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnegY = p_exp*1648\n",
    "pnegY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932.6855999999999"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnegN = (1-p_exp)*1648\n",
    "pnegN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7965.6856"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pposY = p_exp*18352\n",
    "pposY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10386.3144"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pposN = (1-p_exp)*18352\n",
    "pposN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np and nqs are all greater than 10. We can use CLT to calculate z-score, p-values and confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.44, 3.1733766408965351e-17, 0.065, 0.104)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ZscoreProp(num1, num2, size1, size2):\n",
    "    num1, num2, size1, size2 = float(num1), float(num2), float(size1), float(size2)\n",
    "    prop1 = num1/size1\n",
    "    prop2 = num2/size2\n",
    "    teststat = abs(prop1 - prop2)\n",
    "    p_exp = (num1 + num2)/(size1+size2)\n",
    "    std_err = round(np.sqrt(p_exp*(1-p_exp)*(1/size1 + 1/size2)), 2)\n",
    "    z_score = round(teststat/std_err, 2)\n",
    "    p_value = st.norm.sf(z_score)*2\n",
    "    conf1 = round(teststat - (1.96*std_err), 3)\n",
    "    conf2 = round(teststat + (1.96*std_err), 3)\n",
    "    return z_score, p_value, conf1, conf2\n",
    "ZscoreProp(7838, 843, 18352, 1648)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a p-value < .001, we can say with 95% confidence that negative reviewers are likely to get more helpfulness ratings the 8-9% range.\n",
    "\n",
    "we can also use statsmodels stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.901647619219666, 4.4057541906528601e-38)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats import proportion\n",
    "sms.proportions_ztest(np.array([7838.0, 843.0]), np.array([18352.0, 1648.0]),value= 0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the Whole population: we can calculate confidence interval here too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8157203, 738669)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3499532.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[df.overall=='positive'].percHelpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373310.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df[df.overall =='negative'].percHelpful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126.77, 0.0, 0.075, 0.078)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ZscoreProp1(num1, num2, size1, size2):\n",
    "    num1, num2, size1, size2 = float(num1), float(num2), float(size1), float(size2)\n",
    "    prop1 = num1/size1\n",
    "    prop2 = num2/size2\n",
    "    teststat = abs(prop1 - prop2)\n",
    "    p_exp = (num1 + num2)/(size1+size2)\n",
    "    std_err = np.sqrt(p_exp*(1-p_exp)*(1/size1 + 1/size2))\n",
    "    z_score = round(teststat/std_err, 2)\n",
    "    p_value = st.norm.sf(z_score)*2\n",
    "    conf1 = round(teststat - (1.96*std_err), 3)\n",
    "    conf2 = round(teststat + (1.96*std_err), 3)\n",
    "    return z_score, p_value, conf1, conf2\n",
    "ZscoreProp1(3499532.0, 373310.0, 8157203.0, 738669.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the confidence interval is very narrow because we have the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation\n",
    "\n",
    "We see that negative reviews are likely to be more helpful. However, it does not mean that positive reviews are not helpful. We have to examine ratings, length of the reviews and the helpfulness rating of reviewers to make that decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
